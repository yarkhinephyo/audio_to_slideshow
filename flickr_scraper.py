# Generated by Glenn Jocher (glenn.jocher@ultralytics.com) for https://github.com/ultralytics

import argparse
import os
import time

import requests
from flickrapi import FlickrAPI

from config import FLICKR_KEY, FLICKR_SECRET, LICENSE_TYPES


def download_uri(uri, dir='./'):
    with open(dir + uri.split('/')[-1], 'wb') as f:
        f.write(requests.get(uri, stream=True).content)


def get_urls(search, dir_path, n=10):
    """Given a search term, retrieves the top 10 relevant photos and downloads it into dir_path

    Args:
        search (str): Search Term
        dir_path (str): Subdirectory Path
        n (int, optional): Top Num Of Photos. Defaults to 10
    """
    t = time.time()
    flickr = FlickrAPI(FLICKR_KEY, FLICKR_SECRET)
    photos = flickr.walk(text=search,
                         extras=['url_o', 'license'],
                         per_page=100,
                         sort='relevance',
                         license=LICENSE_TYPES)

    if not os.path.exists(dir_path):
        os.makedirs(dir_path)

    urls = []
    for i, photo in enumerate(photos):
        if i == n:
            break

        try:
            # construct url https://www.flickr.com/services/api/misc.urls.html
            url = photo.get('url_o')  # original size
            if url is None:
                url = 'https://farm%s.staticflickr.com/%s/%s_%s_b.jpg' % \
                      (photo.get('farm'), photo.get('server'), photo.get(
                          'id'), photo.get('secret'))  # large size

            download_uri(url, dir_path + os.sep)

            urls.append(url)
        except:
            print('%g/%g error...' % (i, n))
